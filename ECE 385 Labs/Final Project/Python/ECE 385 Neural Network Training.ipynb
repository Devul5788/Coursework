{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12735cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the dataset\n",
    "np.random.seed(2)\n",
    "\n",
    "'load the dataset'\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "\"creating label\"\n",
    "y = dataset[\"label\"]\n",
    "\n",
    "\"dropping label\"\n",
    "X = dataset.drop(labels = [\"label\"], axis = 1)\n",
    "\n",
    "\"deleting dataset to reduce memory usage\"\n",
    "del dataset\n",
    "\n",
    "'overview of dataset'\n",
    "g = sns.countplot(y)\n",
    "y.value_counts()\n",
    "\n",
    "'Grayscale normalization to reduce the effect of illumination differences.'\n",
    "X = X / 255.0\n",
    "\n",
    "'''\n",
    "reshaping the dataset to fit standard of a 4D tensor of shape [mini-batch size, height = 28px, width = 28px, channels = 1 due to grayscale].\n",
    "-1 for reshape means unknown (python will figure out this dimension itself by looking at the number of elements left) Batch size in this case\n",
    "is going to be the number of images. 28x28 is the x and y values of the image. We are essentially reshaping 1D array of pixel values ranging from\n",
    "0 to 255 into 2D array of size 28x28'\n",
    "'''\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "\n",
    "'categorical conversion of label. 10 numbers and 4 operations. Converts it to hot bit vectors'\n",
    "y = to_categorical(y, num_classes = 14)\n",
    "\n",
    "'90% Training and 10% Validation split'\n",
    "random_seed = 2\n",
    "X_train, X_test, y_train, y_tes = train_test_split(X, y, test_size = 0.1 , random_state = random_seed, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa164a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "'creating the instance of the model'\n",
    "model = Sequential()\n",
    "\n",
    "'''\n",
    "adding layers to the model'\n",
    "First, a set of two Convolutional layers (32 filters and ReLU activation function) to identify the low level image patterns (lines, edges, etc.).\n",
    "Next, the Max Pooling layer (pooling size of 2 X 2) simply downsamples the filters to reduce computational load, memroy usage and number of parameters.\n",
    "Finally, a Dropout is used as regularization method. It randomly ignore 25% of the nodes during every training iteration.\n",
    "filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "\"same\" results in padding with zeros evenly to the left/right or up/down of the input\n",
    "input shape is each picture in the 4D kernel - (x, y, channels = 1)\n",
    "'''\n",
    "#Layer: 1\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "'''\n",
    "A set of two Convolutional layers (64 filters and ReLU activation function) to identify complex patterns that are a combination of lower-level patterns detected by the first layer.\n",
    "Max Pooling layer (pooling size of 2 X 2) for downsampling.\n",
    "Dropout for regularization.\n",
    "'''\n",
    "#Layer: 2\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "'''\n",
    "First, a Flatten layer is use to convert the final feature maps into a single 1D vector (necessary for Dense layer input).\n",
    "Next, a fully-connected (Dense) layer that acts as an Artificial Neural Network.\n",
    "Dropout for regularization.\n",
    "Finally, another fully-connected (Dense) layers with Softmax activation as the output layer. The softmax function takes the \n",
    "elements of the output layer and transforms them into a net output distribution of the probability of each class. The class with the highest probability is taken as the model prediction.\n",
    "'''\n",
    "#fully connected layer and output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(14, activation = \"softmax\"))\n",
    "\n",
    "'''\n",
    "Set the optimizer and annealer\n",
    "The loss function measures the error rate between the observed and predicted labels. For this model, categorical_crossentropy is used as th loss function.\n",
    "Next, the famous RMSprop is used as the optimizer algorithm to iteratively improves various model parameters. RMSprop is also one of the fastest optimizers.\n",
    "The metric function “accuracy” is used as the score function to evaluate the performance our model.\n",
    "In order to make the optimizer converge faster and closest to the global minimum of the loss function, the ReduceLROnPlateau function from Keras.callbacks is used as an annealing method of the learning rate (LR).\n",
    "optimizer = RMSprop(learning_rate = 0.001, rho = 0.9, epsilon = 1e-08, decay=0.0 )\n",
    "'''\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = \"val_accuracy\",\n",
    "                                            patience = 3,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            min_lr = 0.0001)\n",
    "\n",
    "'''\n",
    "'data augmentation\n",
    "Data augmentation is a set of techniques to artificially increase the amount of data by generating new data points from existing data.\n",
    "This includes making small changes to data or using deep learning models to generate new data points.\n",
    "'''\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "'fitting the model'\n",
    "epochs = 5\n",
    "batch_size = 86\n",
    "\n",
    "'history allows us to see the accuracy as well as other things for each epoch'\n",
    "history = model.fit(\n",
    "                                datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                                epochs = epochs, #An epoch is an iteration over the entire x and y data provided\n",
    "                                validation_data = (X_val,y_val), #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                                verbose = 2, #output\n",
    "                                steps_per_epoch=X_train.shape[0] // batch_size,  # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
    "                                callbacks=[learning_rate_reduction]                            \n",
    "                              )\n",
    "\n",
    "'saving the model HDF5 binary data format'\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59851355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and Training CNN Model\n",
    "from PIL import Image\n",
    "from itertools import groupby\n",
    "\n",
    "'loading image'\n",
    "image = Image.open(\"testing2.png\").convert(\"L\")\n",
    "\n",
    "'resizing to 28 height pixels'\n",
    "w = image.size[0]\n",
    "h = image.size[1]\n",
    "r = w / h # aspect ratio\n",
    "\n",
    "'image is resized to a height of 28 px (model input requirement). Keeping the same aspect ratio, the width is adjusted as well.'\n",
    "new_w = int(r * 28)\n",
    "new_h = 28\n",
    "new_image = image.resize((new_w, new_h))\n",
    "\n",
    "'converting to a numpy array'\n",
    "new_image_arr = np.array(new_image)\n",
    "\n",
    "'inverting the image to make background = 0. Black is 0. White is 255'\n",
    "new_inv_image_arr = 255 - new_image_arr\n",
    "\n",
    "'rescaling the image'\n",
    "final_image_arr = new_inv_image_arr / 255.0\n",
    "\n",
    "'''\n",
    "splitting image array into individual digit arrays using non zero columns\n",
    "Now the image array is split into individual element arrays.\n",
    "This is done by searching the image array for successive non zero columns (non black) and grouping them to form one element array.\n",
    "These element arrays are all stored in one list. If there are 14 elements in the mathematical expression, the size of the list will be 14.\n",
    "'''\n",
    "m = final_image_arr.any(0)\n",
    "out = [final_image_arr[:,[*g]] for k, g in groupby(np.arange(len(m)), lambda x: m[x] != 0) if k]\n",
    "\n",
    "\n",
    "'''\n",
    "iterating through the digit arrays to resize them to match input \n",
    "criteria of the model = [mini_batch_size, height, width, channels]\n",
    "'''\n",
    "num_of_elements = len(out)\n",
    "elements_list = []\n",
    "'''\n",
    "In order to identify the element using the model, it is important to have the image size of 28px*28px. The height is already 28px.\n",
    "However, due to the splitting process, the width of each element is not exactly 28px.\n",
    "Therefore, after the splitting, the width of each element is adjusted to 28 px. by adding zero value columns (filler columns) to the element arrays.\n",
    "'''\n",
    "for x in range(0, num_of_elements):\n",
    "    img = out[x]\n",
    "    \n",
    "    #adding 0 value columns as fillers\n",
    "    width = img.shape[1]\n",
    "    filler = (final_image_arr.shape[0] - width) / 2\n",
    "    \n",
    "    if filler.is_integer() == False:    #odd number of filler columns\n",
    "        filler_l = int(filler)\n",
    "        filler_r = int(filler) + 1\n",
    "    else:                               #even number of filler columns\n",
    "        filler_l = int(filler)\n",
    "        filler_r = int(filler)\n",
    "    \n",
    "    arr_l = np.zeros((final_image_arr.shape[0], filler_l)) #left fillers\n",
    "    arr_r = np.zeros((final_image_arr.shape[0], filler_r)) #right fillers\n",
    "    \n",
    "    #concatinating the left and right fillers\n",
    "    help_ = np.concatenate((arr_l, img), axis= 1)\n",
    "    element_arr = np.concatenate((help_, arr_r), axis= 1)\n",
    "    \n",
    "    element_arr.resize(28, 28, 1) #resize array 2d to 3d\n",
    "\n",
    "    #storing all elements in a list\n",
    "    elements_list.append(element_arr)\n",
    "\n",
    "\n",
    "elements_array = np.array(elements_list)\n",
    "\n",
    "'the elements list is converted back into an array of shape (14, 28, 28, 1) to fit the model input requirements of a 4D Tensor'\n",
    "elements_array = elements_array.reshape(-1, 28, 28, 1)\n",
    "\n",
    "'predicting using the model'\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "elements_pred =  model.predict(elements_array)\n",
    "\n",
    "'The class with the highest probability is chosen.'\n",
    "elements_pred = np.argmax(elements_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63cb4c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid predicted expression!!\n",
      "Following is the predicted expression:\n",
      "4 - 1 -\n"
     ]
    }
   ],
   "source": [
    "#Creating the math calculator\n",
    "def math_expression_generator(arr):\n",
    "    op = {\n",
    "              10,   # = \"/\"\n",
    "              11,   # = \"+\"\n",
    "              12,   # = \"-\"\n",
    "              13    # = \"*\"\n",
    "                  }   \n",
    "    \n",
    "    'creating a list separating all elements'\n",
    "    'm_exp would become [9, 8], 10, [7, 6], 13, [5, 4], 11, [3, 2], 12, [1, 0]] --> 98 / 76 * 54 + 32 - 10 = 91.63'\n",
    "    m_exp = []\n",
    "    temp = []\n",
    "    for item in arr:\n",
    "        if item not in op:\n",
    "            temp.append(item)\n",
    "        else:\n",
    "            m_exp.append(temp)\n",
    "            m_exp.append(item)\n",
    "            temp = []\n",
    "    if temp:\n",
    "        m_exp.append(temp)\n",
    "    \n",
    "    'converting the elements to numbers and operators'\n",
    "    'so things like [9, 8] in m_exp are converted to the number 98'\n",
    "    i = 0\n",
    "    num = 0\n",
    "    for item in m_exp:\n",
    "        if type(item) == list:\n",
    "            if not item:\n",
    "                m_exp[i] = \"\"\n",
    "                i = i + 1\n",
    "            else:\n",
    "                num_len = len(item)\n",
    "                for digit in item:\n",
    "                    num_len = num_len - 1\n",
    "                    num = num + ((10 ** num_len) * digit)\n",
    "                m_exp[i] = str(num)\n",
    "                num = 0\n",
    "                i = i + 1\n",
    "        else:\n",
    "            m_exp[i] = str(item)\n",
    "            m_exp[i] = m_exp[i].replace(\"10\",\"/\")\n",
    "            m_exp[i] = m_exp[i].replace(\"11\",\"+\")\n",
    "            m_exp[i] = m_exp[i].replace(\"12\",\"-\")\n",
    "            m_exp[i] = m_exp[i].replace(\"13\",\"*\")\n",
    "            \n",
    "            i = i + 1\n",
    "    \n",
    "    \n",
    "    'joining the list of strings to create the mathematical expression'\n",
    "    separator = ' '\n",
    "    m_exp_str = separator.join(m_exp)\n",
    "    \n",
    "    return (m_exp_str)\n",
    "\n",
    "'creating the mathematical expression'\n",
    "m_exp_str = math_expression_generator(elements_pred)\n",
    "\n",
    "'calculating the mathematical expression using eval()'\n",
    "while True:\n",
    "    try:\n",
    "        answer = eval(m_exp_str)    #evaluating the answer\n",
    "        answer = round(answer, 2)\n",
    "        equation  = m_exp_str + \" = \" + str(answer)\n",
    "        print(equation)   #printing the equation\n",
    "        break\n",
    "\n",
    "    except SyntaxError:\n",
    "        print(\"Invalid predicted expression!!\")\n",
    "        print(\"Following is the predicted expression:\")\n",
    "        print(m_exp_str)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model update\n",
    "'''\n",
    "What makes Machine learning algorithms so powerful is its ability to learn from its mistakes. In order to do that the model needs to be retrained with correct information.'\n",
    "When there is a false prediction, the above code asks for the correct mathematical expression from the user. It then compares the predicted with the correct expression and identifies the elements that are wrongly predicted.\n",
    "The code then trains the model from its second hidden layer till its output layer using the correct data (first hidden layer is not trained).\n",
    "The updated model is saved and can be used later to make improved predictions.\n",
    "'''\n",
    "def model_update(X, y, model):\n",
    "    \n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "      \n",
    "    y = to_categorical(y, num_classes = 14)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    datagen.fit(X)\n",
    "\n",
    "    #freezing layers 0 to 4\n",
    "    for l in range(0, 5):\n",
    "        model.layers[l].trainable = False\n",
    "\n",
    "    optimizer = RMSprop(lr = 0.0001, rho = 0.9, epsilon = 1e-08, decay=0.0 )\n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "        \n",
    "    history = model.fit(\n",
    "                            datagen.flow(X,y, batch_size = 1),\n",
    "                            epochs = 50,\n",
    "                            verbose = 1\n",
    "                        )\n",
    "    \n",
    "    'saving the model'\n",
    "    model.save(\"updated_model.h5\") \n",
    "    \n",
    "    print(\"Model has been updated!!\")\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "\n",
    "'taking user feedback regarding prediction'\n",
    "feedback = input(\"Was the expression correctly predicted? (y/n): \")\n",
    "\n",
    "'if no then, asking user for correct expression'\n",
    "if feedback == \"n\":\n",
    "    corr_ans_str = str(input(\"The correct expression is: \"))\n",
    "    corr_ans_str = corr_ans_str.replace(\" \", \"\")\n",
    "    \n",
    "    def feedback_conversion(correct_ans_str):\n",
    "        return [char for char in correct_ans_str]\n",
    "    \n",
    "    corr_ans_list = feedback_conversion(corr_ans_str)\n",
    "    dic = {\"/\":\"10\", \"+\": \"11\", \"-\": \"12\", \"*\": \"13\"}  \n",
    "    corr_ans_list = [dic.get(n, n) for n in corr_ans_list]\n",
    "    corr_ans_arr= np.array(list(map(int, corr_ans_list)))\n",
    "    print(corr_ans_arr.shape)\n",
    "    \n",
    "    'comparing the expressions and getting the indexes of the wrong predictioned elements'\n",
    "    wrong_pred_indices = []\n",
    "    \n",
    "    for i in range(len(corr_ans_arr)):\n",
    "        if corr_ans_arr[i] == elements_pred[i]:\n",
    "            pass\n",
    "        else:\n",
    "            wrong_pred_indices.append(i)\n",
    "    \n",
    "    'picking up the wrongly predicted elements'\n",
    "    X = elements_array[[wrong_pred_indices]]\n",
    "    \n",
    "    'reshaping to fit model input standards'\n",
    "    if len(X.shape) == 3:\n",
    "        X = X.reshape(-1, 28, 28, 1)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    'the correct answers as labels'\n",
    "    y = corr_ans_arr[[wrong_pred_indices]]\n",
    "    \n",
    "    'updating the model'\n",
    "    model_update(X, y, model)    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    'if expression is correctly predicted'\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
